print("USING backend/tests/conftest.py")

import asyncio
import pytest
import pytest_asyncio
from typing import AsyncGenerator, Dict, Any, Optional, Union, List, Generator
from fastapi import FastAPI, APIRouter, Depends, HTTPException
from fastapi.testclient import TestClient
from httpx import AsyncClient
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker, AsyncEngine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import NullPool
from redis.asyncio import Redis
from sqlalchemy import text
import logging
from fastapi.responses import JSONResponse
import time
from fastapi import status
from starlette.middleware.exceptions import ExceptionMiddleware
import os
import sys
from pathlib import Path
import json
from unittest.mock import AsyncMock

from app.core.errors import (
    AppError,
    NotFoundError,
    ValidationError,
    app_error_handler,
    validation_error_handler,
    generic_error_handler,
    setup_error_handlers
)
from app.api.router import router as api_router
from app.db.base import Base
from app.core.monitoring import RateLimiter, TelemetryService
from app.core.config import settings, Settings
from app.core.redis import RedisClient
from app.api.deps import get_db, get_redis, get_settings, get_websocket_manager
from app.main import app as main_app
from app.core.websocket import WebSocketManager
from app.tests.utils.user import create_random_user
from app.models.user import User

# Configure logging for tests
def setup_test_logging():
    """Configure logging for tests with debug level and console output."""
    # Remove all existing handlers
    root_logger = logging.getLogger()
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    # Set up console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.DEBUG)
    
    # Use a more readable format for tests
    test_formatter = logging.Formatter(
        '\n%(asctime)s %(levelname)s [%(name)s] %(message)s\n  File "%(pathname)s", line %(lineno)d\n'
    )
    console_handler.setFormatter(test_formatter)
    
    # Configure root logger
    root_logger.setLevel(logging.DEBUG)
    root_logger.addHandler(console_handler)
    
    # Configure app loggers
    for logger_name in ['app', 'tests', 'websockets', 'aiohttp', 'fastapi']:
        logger = logging.getLogger(logger_name)
        logger.setLevel(logging.DEBUG)
        logger.addHandler(console_handler)
        logger.propagate = False

# Set up logging at module import
setup_test_logging()

# Configure logger
logger = logging.getLogger(__name__)

# Test database URL - use environment variables with fallbacks
POSTGRES_USER = os.getenv("POSTGRES_USER", "postgres")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD", "postgres")
POSTGRES_HOST = os.getenv("POSTGRES_HOST", "db-test")
POSTGRES_PORT = os.getenv("POSTGRES_PORT", "5432")
POSTGRES_DB = os.getenv("POSTGRES_DB", "test_mcp_chat")

# Use SQLite for local testing, PostgreSQL for Docker tests
TEST_SQLALCHEMY_DATABASE_URL = (
    "sqlite+aiosqlite:///:memory:"
    if os.getenv("TEST_DB") == "sqlite"
    else f"postgresql+asyncpg://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}"
)

@pytest.fixture(scope="session")
def test_settings() -> Settings:
    """Override settings for testing."""
    return Settings(
        POSTGRES_USER=POSTGRES_USER,
        POSTGRES_PASSWORD=POSTGRES_PASSWORD,
        POSTGRES_HOST=POSTGRES_HOST,
        POSTGRES_PORT=POSTGRES_PORT,
        POSTGRES_DB=POSTGRES_DB,
        SQLALCHEMY_DATABASE_URI=TEST_SQLALCHEMY_DATABASE_URL,  # Set both for compatibility
        DATABASE_URL=TEST_SQLALCHEMY_DATABASE_URL,
        NODE_ENV="test"  # Ensure we're in test mode
    )

# Test Redis URL
TEST_REDIS_URL = f"redis://{os.getenv('REDIS_HOST', 'redis-test')}:{os.getenv('REDIS_PORT', '6379')}/1"

# Docker service configuration
DOCKER_SERVICE_HOST = os.getenv("DOCKER_SERVICE_HOST", "localhost")
DOCKER_SERVICE_PORT = int(os.getenv("DOCKER_SERVICE_PORT", "8000"))

# Base URL for tests
TEST_BASE_URL = f"http://{DOCKER_SERVICE_HOST}:{DOCKER_SERVICE_PORT}"

# Create test engine with connection pooling
engine = create_async_engine(
    TEST_SQLALCHEMY_DATABASE_URL,
    echo=True,
    future=True,
    pool_size=5,
    max_overflow=10,
    pool_timeout=30,
    pool_recycle=1800,  # Recycle connections after 30 minutes
    pool_pre_ping=True  # Enable connection health checks
)
async_session = async_sessionmaker(engine, expire_on_commit=False)

# Test router for error handling tests
test_router = APIRouter()

@test_router.get("/test/app-error")
async def test_app_error():
    """Test endpoint that raises an AppError."""
    raise AppError("Test error message", code="test_error")

@test_router.get("/test/not-found")
async def test_not_found():
    """Test endpoint that raises a NotFoundError."""
    raise NotFoundError("Resource not found")

@test_router.get("/test/validation-error")
async def test_validation_error():
    """Test endpoint that raises a ValidationError."""
    raise ValidationError("Invalid data", errors={"field": "error"})

@test_router.get("/test/generic-error")
async def test_generic_error():
    """Test endpoint that raises a generic error."""
    try:
        raise Exception("Internal server error")
    except Exception as e:
        # Return error response directly
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content={
                "error": str(e) if settings.DEBUG else "Internal server error",
                "code": "internal_server_error"
            }
        )

@pytest.fixture(scope="session")
def event_loop() -> Generator:
    """Create an instance of the default event loop for the test session."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest_asyncio.fixture(scope="session")
async def test_engine() -> AsyncEngine:
    """Create a test database engine."""
    engine = create_async_engine(
        TEST_SQLALCHEMY_DATABASE_URL,
        echo=True,
        future=True,
        poolclass=NullPool  # Disable connection pooling for tests
    )
    
    yield engine
    await engine.dispose()

@pytest_asyncio.fixture(autouse=True)
async def setup_test_db(test_engine: AsyncEngine) -> None:
    """Set up test database before tests."""
    try:
        # Drop all tables
        async with test_engine.begin() as conn:
            await conn.run_sync(Base.metadata.drop_all)
        
        # Create all tables
        async with test_engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
            
        yield
        
        # Clean up after tests
        async with test_engine.begin() as conn:
            await conn.run_sync(Base.metadata.drop_all)
    except Exception as e:
        print(f"Error setting up test database: {str(e)}")
        raise

@pytest_asyncio.fixture
async def db(test_engine: AsyncEngine) -> AsyncGenerator[AsyncSession, None]:
    """Get a database session for testing."""
    async_session = sessionmaker(
        test_engine, class_=AsyncSession, expire_on_commit=False
    )
    
    async with async_session() as session:
        yield session
        await session.rollback()
        await session.close()

@pytest_asyncio.fixture
async def test_user(db: AsyncSession) -> AsyncGenerator[User, None]:
    """Create a random user for testing and clean up afterwards."""
    user = None
    try:
        user = await create_random_user(db)
        yield user
    finally:
        if user:
            try:
                # Use the same session to delete the user
                await db.delete(user)
                await db.commit()
            except Exception as e:
                logger.error(f"Error cleaning up test_user {user.id}: {e}")
                await db.rollback() # Rollback potential failed delete transaction

@pytest.fixture
def websocket_manager(redis_client: RedisClient) -> WebSocketManager:
    """Create a fresh WebSocket manager for each test."""
    manager = WebSocketManager(redis_client)
    yield manager
    # Clean up after test
    manager.message_history.clear()
    manager.message_by_id.clear()
    manager.active_connections.clear()
    manager.connection_metadata.clear()
    manager.user_connections.clear()

@pytest_asyncio.fixture
async def manager(websocket_manager: WebSocketManager, redis_client: RedisClient) -> WebSocketManager:
    """Configure WebSocket manager with Redis client.
       Note: This fixture provides the *configured* manager instance for tests.
       The `websocket_manager` fixture provides a fresh, unconfigured instance.
    """
    websocket_manager.redis_client = redis_client
    # Clear any existing state
    websocket_manager.message_history.clear()
    websocket_manager.message_by_id.clear()
    websocket_manager.active_connections.clear()
    websocket_manager.connection_metadata.clear()
    websocket_manager.user_connections.clear()
    return websocket_manager

@pytest.fixture
def test_client(app: FastAPI) -> TestClient:
    """Create a test client that supports WebSocket connections."""
    return TestClient(app)

@pytest.fixture(scope="session")
def docker_compose_file(pytestconfig):
    """Get the Docker compose file path."""
    return os.path.join(str(pytestconfig.rootdir), "docker-compose.test.yml")

@pytest.fixture(scope="session")
def docker_compose_project_name():
    """Get the Docker compose project name."""
    return "mcp-chat-test"

@pytest_asyncio.fixture
async def app(redis_client: RedisClient, manager: WebSocketManager, test_engine: AsyncEngine, test_settings: Settings) -> FastAPI:
    """Create a test FastAPI application with proper dependency overrides."""
    
    # Use a copy of the main app to avoid modifying the original
    test_app = main_app
    
    # Correctly override get_db dependency
    async def override_get_db() -> AsyncGenerator[AsyncSession, None]:
        async with async_sessionmaker(test_engine, expire_on_commit=False)() as session:
            yield session
            
    test_app.dependency_overrides[get_db] = override_get_db
    test_app.dependency_overrides[get_redis] = lambda: redis_client # Use test redis fixture
    test_app.dependency_overrides[get_settings] = lambda: test_settings # Override get_settings
    test_app.dependency_overrides[get_websocket_manager] = lambda: manager # Override websocket manager
    
    # Configure test settings instance (moved from manager fixture)
    test_settings.WEBSOCKET_PING_INTERVAL = 1
    test_settings.WEBSOCKET_PING_TIMEOUT = 2
    test_settings.MAX_CONNECTIONS_PER_USER = 5
    
    # Remove direct patching of the manager
    # import app.core.websocket
    # app.core.websocket.manager = manager 
    
    # Add error handlers (ensure this happens on the test_app instance)
    # Check if handlers are already added to avoid duplicates if app fixture is reused
    if not any(isinstance(middleware.cls, ExceptionMiddleware) for middleware in test_app.user_middleware):
        setup_error_handlers(test_app)
    
    # Add routes (ensure this happens on the test_app instance)
    if test_router not in test_app.routes:
         test_app.include_router(test_router) 
    
    return test_app

@pytest_asyncio.fixture
async def client(app: FastAPI) -> AsyncGenerator[TestClient, None]:
    """Create an async test client - yielding TestClient for WS support."""
    # Yield TestClient instead of AsyncClient
    with TestClient(app=app, base_url="http://test") as test_client:
        # Simplified Readiness Check (using test_client hitting health endpoint)
        health_path = "/health" # Adjust if your health endpoint is different
        max_retries = 10
        retry_count = 0
        db_ready = False # Renamed for clarity
        while retry_count < max_retries:
            try:
                response = test_client.get(health_path)
                if response.status_code == 200:
                     db_ready = True
                     logger.info(f"Health check successful at {health_path}.")
                     break
                else:
                    logger.warning(f"Health check failed with status: {response.status_code}")
            except Exception as e:
                logger.warning(f"Health check request failed: {str(e)}")
            
            retry_count += 1
            if retry_count == max_retries:
                 raise RuntimeError(f"Health check endpoint {health_path} not ready after {max_retries} attempts.")
            await asyncio.sleep(min(retry_count * 0.5, 5)) # Use shorter backoff
        
        if not db_ready:
             raise RuntimeError("Service readiness check failed within client fixture.")
             
        yield test_client # Yield the TestClient

@pytest.fixture
def sync_client(app: FastAPI) -> Generator:
    """Create a synchronous test client."""
    with TestClient(app, base_url="http://test") as client:
        yield client

class MockRedisPipeline:
    """Mock Redis pipeline implementation for testing."""
    
    def __init__(self, redis_instance):
        self.redis = redis_instance
        self.transaction = False
        self.watched_keys = set()
        self.commands = []
        self.results = []

    async def watch(self, *keys):
        """Watch keys for changes."""
        self.watched_keys.update(keys)
        return True

    async def multi(self):
        """Start a transaction."""
        self.transaction = True
        return True

    async def execute(self):
        """Execute all commands in the pipeline."""
        results = []
        for cmd, *args in self.commands:
            if cmd == "get":
                results.append(await self.redis.get(args[0]))
            elif cmd == "set":
                results.append(await self.redis.set(args[0], args[1], args[2]))
            elif cmd == "hset":
                results.append(await self.redis.hset(args[0], args[1], args[2]))
            elif cmd == "hget":
                results.append(await self.redis.hget(args[0], args[1]))
            elif cmd == "hincrby":
                results.append(await self.redis.hincrby(args[0], args[1], args[2]))
            elif cmd == "hgetall":
                results.append(await self.redis.hgetall(args[0]))
            elif cmd == "incr":
                results.append(await self.redis.incr(args[0]))
            elif cmd == "expire":
                results.append(await self.redis.expire(args[0], args[1]))
            elif cmd == "delete":
                results.append(await self.redis.delete(args[0]))
        
        self.commands = []
        self.transaction = False
        return results

    async def get(self, key: str):
        """Add get command to pipeline."""
        self.commands.append(("get", key))
        return self

    async def set(self, key: str, value: Any, ex: Optional[int] = None):
        """Add set command to pipeline."""
        self.commands.append(("set", key, value, ex))
        return self

    async def hset(self, key: str, field: str, value: Any):
        """Add hset command to pipeline."""
        self.commands.append(("hset", key, field, value))
        return self

    async def hget(self, key: str, field: str):
        """Add hget command to pipeline."""
        self.commands.append(("hget", key, field))
        return self

    async def hincrby(self, key: str, field: str, amount: int = 1):
        """Add hincrby command to pipeline."""
        self.commands.append(("hincrby", key, field, amount))
        return self

    async def hgetall(self, key: str):
        """Add hgetall command to pipeline."""
        self.commands.append(("hgetall", key))
        return self

    async def incr(self, key: str):
        """Add incr command to pipeline."""
        self.commands.append(("incr", key))
        return self

    async def expire(self, key: str, seconds: int):
        """Add expire command to pipeline."""
        self.commands.append(("expire", key, seconds))
        return self

    async def delete(self, key: str):
        """Add delete command to pipeline."""
        self.commands.append(("delete", key))
        return self

class MockRedis:
    """Mock Redis implementation for testing."""
    
    def __init__(self):
        self._data = {}
        self._hash_data = {}
        self._list_data = {}
        self._expires = {}
        self._expire_times = {}  # Store actual expiration timestamps

    async def ping(self):
        """Test Redis connection."""
        return True

    async def get(self, key: str) -> Optional[bytes]:
        """Get a value from Redis."""
        # Check if key has expired
        if key in self._expire_times:
            if time.time() >= self._expire_times[key]:
                # Key has expired
                del self._data[key]
                del self._expires[key]
                del self._expire_times[key]
                return None
            
        if key in self._data:
            value = self._data[key]
            # Return the value as bytes, as Redis would
            if isinstance(value, str):
                return value.encode()
            elif isinstance(value, bytes):
                return value
            else:
                # For non-string/bytes values, JSON encode them
                return json.dumps(value).encode()
        return None

    async def set(
        self,
        key: str,
        value: Union[str, bytes, int],
        ex: Optional[int] = None
    ) -> bool:
        """Set a value in Redis."""
        # Store the value as is, without any conversion
        # Redis would handle the conversion to bytes
        if isinstance(value, bytes):
            # If it's bytes, try to decode it as JSON first
            try:
                self._data[key] = json.loads(value.decode())
            except json.JSONDecodeError:
                # If it's not JSON, store it as bytes
                self._data[key] = value
        else:
            # For non-bytes values, store them as is
            self._data[key] = value
        
        if ex is not None:
            self._expires[key] = ex
            self._expire_times[key] = time.time() + ex
        return True

    async def delete(self, key: str) -> bool:
        """Delete a key from Redis."""
        if key in self._data:
            del self._data[key]
            if key in self._expires:
                del self._expires[key]
            if key in self._expire_times:
                del self._expire_times[key]
            return True
        return False

    async def exists(self, key: str) -> bool:
        """Check if a key exists in Redis."""
        # Check expiration first
        if key in self._expire_times and time.time() >= self._expire_times[key]:
            # Key has expired
            del self._data[key]
            del self._expires[key]
            del self._expire_times[key]
            return False
        return key in self._data

    async def expire(self, key: str, seconds: int) -> bool:
        """Set an expiration on a key."""
        if key in self._data:
            self._expires[key] = seconds
            self._expire_times[key] = time.time() + seconds
            return True
        return False

    async def ttl(self, key: str) -> int:
        """Get the TTL of a key."""
        return self._expires.get(key, -1)

    async def incr(self, key: str) -> int:
        """Increment a counter."""
        # Check expiration first
        if key in self._expire_times and time.time() >= self._expire_times[key]:
            # Key has expired
            del self._data[key]
            del self._expires[key]
            del self._expire_times[key]
            self._data[key] = "0"
            
        if key not in self._data:
            self._data[key] = "0"
        value = int(self._data[key]) + 1
        self._data[key] = str(value)
        return value

    async def hget(self, key: str, field: str) -> Optional[bytes]:
        """Get a hash field."""
        if key in self._hash_data and field in self._hash_data[key]:
            value = self._hash_data[key][field]
            if isinstance(value, str):
                return value.encode()
            elif isinstance(value, int):
                return str(value).encode()
            return value
        return None

    async def hset(self, key: str, field: str, value: Any) -> int:
        """Set a hash field."""
        if key not in self._hash_data:
            self._hash_data[key] = {}
        self._hash_data[key][field] = value
        return 1

    async def hdel(self, key: str, field: str) -> int:
        """Delete a hash field."""
        if key in self._hash_data and field in self._hash_data[key]:
            del self._hash_data[key][field]
            return 1
        return 0

    async def hgetall(self, key: str) -> Dict[bytes, bytes]:
        """Get all fields in a hash."""
        if key in self._hash_data:
            return {
                k.encode(): str(v).encode()
                for k, v in self._hash_data[key].items()
            }
        return {}

    async def hincrby(self, key: str, field: str, amount: int = 1) -> int:
        """Increment a hash field by the given amount."""
        if key not in self._hash_data:
            self._hash_data[key] = {}
        if field not in self._hash_data[key]:
            self._hash_data[key][field] = 0
        self._hash_data[key][field] = int(self._hash_data[key][field]) + amount
        return self._hash_data[key][field]

    async def lpush(self, key: str, *values: Any) -> int:
        """Push values onto the head of a list."""
        if key not in self._list_data:
            self._list_data[key] = []
        for value in values:
            if isinstance(value, (str, bytes)):
                self._list_data[key].insert(0, value)
            else:
                self._list_data[key].insert(0, str(value))
        return len(self._list_data[key])

    async def lrange(self, key: str, start: int, stop: int) -> List[bytes]:
        """Get a range of elements from a list."""
        if key not in self._list_data:
            return []
        # Handle negative indices
        if start < 0:
            start = max(len(self._list_data[key]) + start, 0)
        if stop < 0:
            stop = max(len(self._list_data[key]) + stop + 1, 0)
        else:
            stop = min(stop + 1, len(self._list_data[key]))
        
        return [
            v.encode() if isinstance(v, str) else v
            for v in self._list_data[key][start:stop]
        ]

    async def ltrim(self, key: str, start: int, stop: int) -> bool:
        """Trim a list to the specified range."""
        if key not in self._list_data:
            return True
        # Handle negative indices
        if start < 0:
            start = max(len(self._list_data[key]) + start, 0)
        if stop < 0:
            stop = max(len(self._list_data[key]) + stop + 1, 0)
        else:
            stop = min(stop + 1, len(self._list_data[key]))
        
        self._list_data[key] = self._list_data[key][start:stop]
        return True

    def pipeline(self) -> MockRedisPipeline:
        """Create a pipeline."""
        return MockRedisPipeline(self)

@pytest_asyncio.fixture
async def redis_client() -> AsyncGenerator[RedisClient, None]:
    """Create a mock Redis client for testing."""
    client = MockRedis()
    yield client
    # No cleanup needed for mock client

@pytest.fixture
async def mock_db():
    """Mock database session for testing."""
    db = AsyncMock()
    db.execute = AsyncMock()
    db.close = AsyncMock()
    return db

@pytest.fixture
async def mock_redis():
    """Mock Redis client for testing."""
    redis = AsyncMock()
    redis.ping = AsyncMock()
    redis.close = AsyncMock()
    return redis

@pytest.fixture
def app(mock_db, mock_redis):
    """Create test FastAPI application."""
    from app.main import app
    app.dependency_overrides = {
        "app.db.base.get_db": lambda: mock_db,
        "app.core.redis.get_redis": lambda: mock_redis
    }
    return app

@pytest.fixture
async def client(app):
    """Create test client."""
    async with AsyncClient(app=app, base_url="http://test") as client:
        yield client 